{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Point transformer denoising implementation\n\n## Using PointTransformer for noise segmentation","metadata":{"id":"U7szutsXmEao","papermill":{"duration":0.044841,"end_time":"2021-06-21T16:06:00.81201","exception":false,"start_time":"2021-06-21T16:06:00.767169","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"# Imports","metadata":{"id":"C4GutaJHmEat","papermill":{"duration":0.042548,"end_time":"2021-06-21T16:06:00.983628","exception":false,"start_time":"2021-06-21T16:06:00.94108","status":"completed"},"tags":[]}},{"cell_type":"code","source":"%load_ext autoreload\n%autoreload 2\n%matplotlib inline","metadata":{"execution":{"iopub.execute_input":"2021-06-21T16:06:01.07714Z","iopub.status.busy":"2021-06-21T16:06:01.073925Z","iopub.status.idle":"2021-06-21T16:06:01.133485Z","shell.execute_reply":"2021-06-21T16:06:01.134519Z","shell.execute_reply.started":"2021-06-21T14:27:46.88534Z"},"id":"Oi5gbToTf2Nb","papermill":{"duration":0.108281,"end_time":"2021-06-21T16:06:01.134855","exception":false,"start_time":"2021-06-21T16:06:01.026574","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install -qq open3d==0.12.0\n!conda install -c conda-forge -y igl >/dev/null","metadata":{"execution":{"iopub.execute_input":"2021-06-21T16:06:01.292627Z","iopub.status.busy":"2021-06-21T16:06:01.291834Z","iopub.status.idle":"2021-06-21T16:07:21.176589Z","shell.execute_reply":"2021-06-21T16:07:21.176103Z","shell.execute_reply.started":"2021-06-21T14:27:46.94098Z"},"papermill":{"duration":79.967112,"end_time":"2021-06-21T16:07:21.176739","exception":false,"start_time":"2021-06-21T16:06:01.209627","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CUDA, = !readlink /usr/local/cuda | sed -E 's/.*cuda-(\\w+)\\.(\\w+)/cu\\1\\2/'\n# !pip install -qq torch-scatter -f https://pytorch-geometric.com/whl/torch-1.7.0+{CUDA}.html\n# !pip install -qq torch-sparse -f https://pytorch-geometric.com/whl/torch-1.7.0+{CUDA}.html\n!pip install -qq torch-cluster -f https://pytorch-geometric.com/whl/torch-1.7.0+{CUDA}.html\n# !pip install -qq torch-geometric","metadata":{"execution":{"iopub.execute_input":"2021-06-21T16:07:21.26898Z","iopub.status.busy":"2021-06-21T16:07:21.268219Z","iopub.status.idle":"2021-06-21T16:07:30.485084Z","shell.execute_reply":"2021-06-21T16:07:30.484534Z","shell.execute_reply.started":"2021-06-21T14:29:32.019543Z"},"papermill":{"duration":9.264868,"end_time":"2021-06-21T16:07:30.485223","exception":false,"start_time":"2021-06-21T16:07:21.220355","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install -Uqq pytorch-lightning\n!pip install -Uqq wandb","metadata":{"execution":{"iopub.execute_input":"2021-06-21T16:07:30.58513Z","iopub.status.busy":"2021-06-21T16:07:30.576845Z","iopub.status.idle":"2021-06-21T16:07:48.182766Z","shell.execute_reply":"2021-06-21T16:07:48.1814Z","shell.execute_reply.started":"2021-06-21T14:29:43.427486Z"},"papermill":{"duration":17.653086,"end_time":"2021-06-21T16:07:48.182909","exception":false,"start_time":"2021-06-21T16:07:30.529823","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !pip install -qq torchtyping","metadata":{"execution":{"iopub.execute_input":"2021-06-21T16:07:48.278856Z","iopub.status.busy":"2021-06-21T16:07:48.272521Z","iopub.status.idle":"2021-06-21T16:07:48.300669Z","shell.execute_reply":"2021-06-21T16:07:48.30028Z","shell.execute_reply.started":"2021-06-21T14:30:08.787935Z"},"papermill":{"duration":0.07451,"end_time":"2021-06-21T16:07:48.300776","exception":false,"start_time":"2021-06-21T16:07:48.226266","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from pathlib import Path\nfrom functools import partial\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom tqdm.auto import tqdm\n\nimport torch\nfrom torch import nn\nfrom torch import optim\n\nfrom torchvision import transforms\n\nfrom torch_cluster import fps\n\nimport pytorch_lightning as pl\n\nfrom sklearn.metrics import confusion_matrix\n\nimport open3d as o3d\nimport igl","metadata":{"execution":{"iopub.execute_input":"2021-06-21T16:07:48.392484Z","iopub.status.busy":"2021-06-21T16:07:48.391695Z","iopub.status.idle":"2021-06-21T16:07:52.308692Z","shell.execute_reply":"2021-06-21T16:07:52.307795Z","shell.execute_reply.started":"2021-06-21T14:30:08.830525Z"},"id":"KgLKXHDkmEau","papermill":{"duration":3.965014,"end_time":"2021-06-21T16:07:52.308833","exception":false,"start_time":"2021-06-21T16:07:48.343819","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pl.__version__","metadata":{"execution":{"iopub.execute_input":"2021-06-21T16:07:52.403062Z","iopub.status.busy":"2021-06-21T16:07:52.398146Z","iopub.status.idle":"2021-06-21T16:07:52.443794Z","shell.execute_reply":"2021-06-21T16:07:52.444219Z","shell.execute_reply.started":"2021-06-21T14:30:13.718581Z"},"papermill":{"duration":0.092513,"end_time":"2021-06-21T16:07:52.444356","exception":false,"start_time":"2021-06-21T16:07:52.351843","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nfrom kaggle_secrets import UserSecretsClient\n\n# Used in kaggle to easily get wandb up and running\nos.environ[\"WANDB_API_KEY\"] = UserSecretsClient().get_secret(\"wandb\")","metadata":{"execution":{"iopub.execute_input":"2021-06-21T16:07:52.53545Z","iopub.status.busy":"2021-06-21T16:07:52.53465Z","iopub.status.idle":"2021-06-21T16:07:52.685887Z","shell.execute_reply":"2021-06-21T16:07:52.685433Z","shell.execute_reply.started":"2021-06-21T14:30:13.779375Z"},"papermill":{"duration":0.198268,"end_time":"2021-06-21T16:07:52.686053","exception":false,"start_time":"2021-06-21T16:07:52.487785","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# TODO: check if there's anything else to seed\nseed = 42\nrng = np.random.default_rng(seed)\ntorch.manual_seed(seed)\ntorch.cuda.manual_seed_all(seed)\n# torch.backends.cudnn.deterministic = True\n# torch.backends.cudnn.benchmark = False","metadata":{"execution":{"iopub.execute_input":"2021-06-21T16:07:52.788723Z","iopub.status.busy":"2021-06-21T16:07:52.787876Z","iopub.status.idle":"2021-06-21T16:07:52.835408Z","shell.execute_reply":"2021-06-21T16:07:52.834928Z","shell.execute_reply.started":"2021-06-21T14:30:14.127642Z"},"papermill":{"duration":0.098657,"end_time":"2021-06-21T16:07:52.835534","exception":false,"start_time":"2021-06-21T16:07:52.736877","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data utilities","metadata":{"id":"2WAyEqzmmEau","papermill":{"duration":0.046432,"end_time":"2021-06-21T16:07:52.932145","exception":false,"start_time":"2021-06-21T16:07:52.885713","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"Sampler\n\nConverters:\n- PointCloudToTensor: point cloud to torch.Tensor\n\nTransforms:\n- PointCloudTranslate: translate point cloud by some value\n- PointCloudRotate: can be used to rotate around any given axis\n- PointCloudRotationalPerturbation\n- PointCloudJitter: clipped Gaussian(0, sigma^2) noise\n- PointCloudDropout\n- PointNormalize\n- **(NOT USED)** PointCloudScale: scale points by some value.\n\nOther:\n- PointShuffle","metadata":{"papermill":{"duration":0.042836,"end_time":"2021-06-21T16:07:53.018828","exception":false,"start_time":"2021-06-21T16:07:52.975992","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Returns 3x3 rotation matrix that rotates by angle around axis\ndef get_rotation_matrix(angle, axis):\n    # Unit vector in axis direction\n    u = axis / np.linalg.norm(axis)\n\n    cross_prod_mat = np.array(\n        [[0.0, -u[2], u[1]],\n        [u[2], 0.0, -u[0]],\n        [-u[1], u[0], 0.0]]\n    )\n\n    cosval, sinval = np.cos(angle), np.sin(angle)\n    rot_matrix = torch.from_numpy(\n        cosval * np.eye(3)\n        + sinval * cross_prod_mat\n        + (1.0 - cosval) * np.outer(u, u)\n    )\n\n    return rot_matrix.float()","metadata":{"execution":{"iopub.execute_input":"2021-06-21T16:07:53.112123Z","iopub.status.busy":"2021-06-21T16:07:53.111362Z","iopub.status.idle":"2021-06-21T16:07:53.153191Z","shell.execute_reply":"2021-06-21T16:07:53.152778Z","shell.execute_reply.started":"2021-06-21T14:30:14.187027Z"},"papermill":{"duration":0.091088,"end_time":"2021-06-21T16:07:53.153314","exception":false,"start_time":"2021-06-21T16:07:53.062226","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Sampler\nclass PointSampler:\n    def __init__(self, num_points: int):\n        self.num_points = num_points\n\n    def __call__(self, x: o3d.geometry.TriangleMesh) -> o3d.geometry.PointCloud:\n        return x.sample_points_uniformly(number_of_points=self.num_points)\n\n\n# Converters\nclass PointCloudToTensor:\n    def __call__(self, x: o3d.geometry.PointCloud) -> torch.Tensor:\n        return torch.from_numpy(np.asarray(x.points)).float()\n\n# Transforms\n# If not stated otherwise, the below transformations work with normals too\nclass PointCloudScale:\n    def __init__(self, lo=0.8, hi=1.25):\n        self.lo, self.hi = lo, hi\n\n    def __call__(self, points):\n        scale_by = rng.uniform(self.lo, self.hi)\n        points[:, 0:3] *= scale_by\n        return points\n\n    \nclass PointCloudTranslate:\n    def __init__(self, translate_range=0.1):\n        self.translate_range = translate_range\n\n    def __call__(self, points):\n        translate_by = rng.uniform(-self.translate_range, self.translate_range)\n        points[:, 0:3] += translate_by\n        return points\n\n\nclass PointCloudRotate:\n    def __init__(self, axis=np.array([0.0, 0.0, 1.0])):\n        self.axis = axis\n\n    def __call__(self, points):\n        rotation_angle = rng.uniform() * 2 * np.pi\n        rotation_matrix = get_rotation_matrix(rotation_angle, self.axis)\n\n        has_normals = points.shape[1] > 3\n        if not has_normals:\n            return torch.matmul(points, rotation_matrix.t())\n        else:\n            pc_xyz = points[:, 0:3]\n            pc_normals = points[:, 3:]\n            points[:, 0:3] = torch.matmul(pc_xyz, rotation_matrix.t())\n            points[:, 3:] = torch.matmul(pc_normals, rotation_matrix.t())\n\n            return points\n\n\nclass PointCloudRotationalPerturbation:\n    def __init__(self, angle_sigma=0.06, angle_clip=0.18):\n        self.angle_sigma, self.angle_clip = angle_sigma, angle_clip\n\n    def _get_angles(self):\n        angles = np.clip(\n            self.angle_sigma * rng.randn(3), -self.angle_clip, self.angle_clip\n        )\n\n        return angles\n\n    def __call__(self, points):\n        angles = self._get_angles()\n        Rx = get_rotation_matrix(angles[0], np.array([1.0, 0.0, 0.0]))\n        Ry = get_rotation_matrix(angles[1], np.array([0.0, 1.0, 0.0]))\n        Rz = get_rotation_matrix(angles[2], np.array([0.0, 0.0, 1.0]))\n\n        # Combined rotation matrix\n        rotation_matrix = torch.matmul(torch.matmul(Rz, Ry), Rx)\n\n        has_normals = points.shape[1] > 3\n        if not has_normals:\n            return torch.matmul(points, rotation_matrix.t())\n        else:\n            pc_xyz = points[:, 0:3]\n            pc_normals = points[:, 3:]\n            points[:, 0:3] = torch.matmul(pc_xyz, rotation_matrix.t())\n            points[:, 3:] = torch.matmul(pc_normals, rotation_matrix.t())\n\n            return points\n        \n\nclass PointCloudJitter:\n    def __init__(self, std=0.01, clip=0.05):\n        self.std, self.clip = std, clip\n\n    def __call__(self, points):\n        jittered_data = (\n            torch.normal(mean=0.0, std=self.std, size=(points.size(0), 3))\n            .clamp_(-self.clip, self.clip)\n        )\n        points[:, 0:3] += jittered_data\n        return points\n\n\n# TODO: rewrite this in torch\nclass PointCloudDropout:\n    def __init__(self, max_dropout_ratio=0.875):\n        assert max_dropout_ratio >= 0 and max_dropout_ratio < 1\n        self.max_dropout_ratio = max_dropout_ratio\n\n    def __call__(self, points):\n        dropout_ratio = rng.random() * self.max_dropout_ratio  # 0~0.875\n        drop_idx = np.where(rng.random((points.shape[0])) <= dropout_ratio)[0]\n        if len(drop_idx) > 0:\n            random_point_idx = rng.choice(list(set(range(points.shape[0])) - set(drop_idx.tolist())), size=1)[0]\n            points[drop_idx, :] = points[random_point_idx].clone()  # set to the random point\n\n        return points\n\n\nclass PointCloudNormalize:\n    def __call__(self, x):\n        x -= torch.mean(x, dim=0)\n        return x / torch.max(x.norm(dim=1))\n\n    \n# Other\nclass PointCloudShuffle:\n    def __call__(self, points):\n        return points[torch.randperm(points.shape[0]), :]","metadata":{"execution":{"iopub.execute_input":"2021-06-21T16:07:53.261782Z","iopub.status.busy":"2021-06-21T16:07:53.260992Z","iopub.status.idle":"2021-06-21T16:07:53.304555Z","shell.execute_reply":"2021-06-21T16:07:53.304148Z","shell.execute_reply.started":"2021-06-21T14:30:14.24376Z"},"papermill":{"duration":0.107893,"end_time":"2021-06-21T16:07:53.304669","exception":false,"start_time":"2021-06-21T16:07:53.196776","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Definitions are here, but actual noise is generated later\nNUM_POINTS = 2048\nNOISE_RATIO = 0.3\nNUM_OBJECT = int(np.floor(NUM_POINTS * (1 - NOISE_RATIO)))\nNUM_NOISE = int(np.ceil(NUM_POINTS * NOISE_RATIO))\nprint(NUM_OBJECT, NUM_NOISE)\nassert NUM_OBJECT + NUM_NOISE == NUM_POINTS\n\n# - Uncomment the transformations that you want to use\n# - Be careful when using PointCloudDropout, e.g. make \n#   sure to select a reasonable dropout ratio\n# - Shuffle does not really do anything because PointTransformer\n#   is invariant to reordering of the points\ntrain_transforms = transforms.Compose([\n    PointSampler(NUM_OBJECT),\n    PointCloudToTensor(),\n#     PointCloudTranslate(),\n#     PointCloudRotate(),\n#     PointCloudRotationalPerturbation(),\n#     PointCloudJitter(),\n#     PointCloudDropout(), # dropout\n#     PointCloudShuffle(), # shuffling points\n    PointCloudNormalize(),\n])\n\nvalid_transforms = transforms.Compose([\n    PointSampler(NUM_OBJECT),\n    PointCloudToTensor(),\n    PointCloudNormalize(),\n])\n\nplotting_transforms = transforms.Compose([\n    PointSampler(NUM_OBJECT),\n    PointCloudToTensor(),\n    PointCloudNormalize(),\n])","metadata":{"execution":{"iopub.execute_input":"2021-06-21T16:07:53.397212Z","iopub.status.busy":"2021-06-21T16:07:53.396447Z","iopub.status.idle":"2021-06-21T16:07:53.43931Z","shell.execute_reply":"2021-06-21T16:07:53.438881Z","shell.execute_reply.started":"2021-06-21T14:30:14.325037Z"},"papermill":{"duration":0.091228,"end_time":"2021-06-21T16:07:53.439423","exception":false,"start_time":"2021-06-21T16:07:53.348195","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load the data","metadata":{"id":"1Jty4tQwmEaw","papermill":{"duration":0.042999,"end_time":"2021-06-21T16:07:53.525752","exception":false,"start_time":"2021-06-21T16:07:53.482753","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def add_jitter_noise(pc, std=0.01, clip=0.001):\n    indices_for_noise = torch.randperm(len(pc))[:NUM_NOISE]\n    noise = pc[indices_for_noise].clone()\n    \n    noise_jitter = torch.normal(mean=0.0, std=std, size=(noise.shape[0], 3))\n    noise[..., :3] += noise_jitter\n    jitter_labels = torch.ones(len(noise), dtype=torch.int32)\n    too_close_indices = noise_jitter.norm(dim=1)\n    too_close_indices = too_close_indices <= clip\n    jitter_labels[too_close_indices] = 0\n\n    y = torch.cat([\n        torch.zeros(len(pc), dtype=torch.int32),\n        jitter_labels\n    ], dim=0)\n    pc = torch.cat([pc, noise], dim=0) # concat noise with pc\n\n    # Permute tensors\n    permutation_idx = torch.randperm(pc.shape[0])\n    pc = pc[permutation_idx, :]\n    y = y[permutation_idx]\n    \n    # Renormalize\n    pc = PointCloudNormalize()(pc)\n    \n    return pc, y","metadata":{"execution":{"iopub.execute_input":"2021-06-21T16:07:53.623466Z","iopub.status.busy":"2021-06-21T16:07:53.622668Z","iopub.status.idle":"2021-06-21T16:07:53.664422Z","shell.execute_reply":"2021-06-21T16:07:53.664029Z","shell.execute_reply.started":"2021-06-21T15:53:47.713668Z"},"papermill":{"duration":0.094985,"end_time":"2021-06-21T16:07:53.664535","exception":false,"start_time":"2021-06-21T16:07:53.56955","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Test\n\n# tns = torch.randn((NUM_OBJECT, 3))\n# pc, y = partial(add_jitter_noise, std=0.15, clip=0.07)(tns)\n# pc.shape, y.shape, pc.mean(dim=0), pc.norm(dim=-1).max(dim=0)[0]","metadata":{"execution":{"iopub.execute_input":"2021-06-21T16:07:53.756191Z","iopub.status.busy":"2021-06-21T16:07:53.755448Z","iopub.status.idle":"2021-06-21T16:07:54.315401Z","shell.execute_reply":"2021-06-21T16:07:54.314776Z","shell.execute_reply.started":"2021-06-21T15:53:48.034739Z"},"papermill":{"duration":0.607708,"end_time":"2021-06-21T16:07:54.315539","exception":false,"start_time":"2021-06-21T16:07:53.707831","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from typing import Tuple, List\n\n\nclass ModelNet40Dataset(torch.utils.data.Dataset):\n\n    ext = \".off\"\n\n    def __init__(\n        self,\n        root: str,\n        split: str,\n        transforms: transforms.Compose,\n        noise_function,\n        subset_ratio=None,\n    ) -> None:\n\n        self.root = Path(root)\n        self.split = split\n        self.transforms = transforms\n        self.noise_function = noise_function\n\n        # Get class labels and mappings\n        dirs = [item.stem for item in self.root.iterdir()]\n        if subset_ratio:\n            dirs = dirs[:int(len(dirs) * subset_ratio)]\n        self.classes = sorted(dirs)\n        print(self.classes)\n        self.idx2class = dict(enumerate(self.classes))\n        print(self.idx2class)\n        \n        self.class2idx = { c: i for i, c in self.idx2class.items() }\n        print(self.class2idx)\n\n        # List files and their labels\n        self.meshes, self.labels = self.get_meshes_and_labels()\n\n    def get_meshes_and_labels(self) -> Tuple[List[str], List[int]]:\n        meshes, labels = [], []\n\n        for i, c in tqdm(list(enumerate(self.classes))):\n            path = self.root / c / self.split\n            for f in tqdm(list(path.glob(f\"*{self.ext}\")), desc=c, leave=False):\n                vertices, triangles = igl.read_triangle_mesh(str(f))\n                mesh = o3d.geometry.TriangleMesh(\n                    o3d.utility.Vector3dVector(vertices),\n                    o3d.utility.Vector3iVector(triangles.astype(np.int32)),\n                )\n                meshes.append(mesh)\n                labels.append(i)\n\n        return meshes, labels\n\n    def __len__(self) -> int:\n        return len(self.meshes)\n\n    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor]:\n        mesh, category = self.meshes[idx], self.labels[idx]\n        x = self.transforms(mesh)\n        x, y = self.noise_function(x)\n\n        return x, y, category","metadata":{"execution":{"iopub.execute_input":"2021-06-21T16:07:54.414928Z","iopub.status.busy":"2021-06-21T16:07:54.414165Z","iopub.status.idle":"2021-06-21T16:07:54.456283Z","shell.execute_reply":"2021-06-21T16:07:54.456682Z","shell.execute_reply.started":"2021-06-21T15:53:57.048867Z"},"papermill":{"duration":0.097206,"end_time":"2021-06-21T16:07:54.456826","exception":false,"start_time":"2021-06-21T16:07:54.35962","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import multiprocessing as mp\n\nclass ModelNet40DataModule(pl.LightningDataModule):\n    def __init__(\n        self, data_dir=\"/kaggle/input/modelnet40/ModelNet40\", batch_size=16,\n        num_workers=mp.cpu_count(),\n        noise_function=partial(add_jitter_noise, std=0.15, clip=0.07)\n    ):\n        super().__init__()\n        self.data_dir = data_dir\n        self.batch_size = batch_size\n        self.num_workers = num_workers\n        self.noise_function = noise_function\n\n    def setup(self, num_points=1024, subset_ratio=None, stage=None):\n        if stage == \"fit\" or stage is None:\n            self.train_dset = ModelNet40Dataset(\n                root=self.data_dir,\n                split=\"train\",\n                transforms=train_transforms,\n                noise_function=self.noise_function,\n                subset_ratio=subset_ratio,\n            )\n            self.val_dset = ModelNet40Dataset(\n                root=self.data_dir,\n                split=\"test\",\n                transforms=valid_transforms,\n                noise_function=self.noise_function,\n                subset_ratio=subset_ratio,\n            )\n\n    def train_dataloader(self):\n        return torch.utils.data.DataLoader(\n            self.train_dset, batch_size=self.batch_size,\n            shuffle=True,\n            drop_last=True,\n            num_workers=self.num_workers,\n            pin_memory=True,\n        )\n\n    def val_dataloader(self):\n        return torch.utils.data.DataLoader(\n            self.val_dset,\n            batch_size=self.batch_size,\n            shuffle=False,\n            drop_last=False,\n            num_workers=self.num_workers,\n            pin_memory=True\n        )","metadata":{"execution":{"iopub.execute_input":"2021-06-21T16:07:54.552917Z","iopub.status.busy":"2021-06-21T16:07:54.552162Z","iopub.status.idle":"2021-06-21T16:07:54.603683Z","shell.execute_reply":"2021-06-21T16:07:54.603001Z","shell.execute_reply.started":"2021-06-21T15:53:57.257521Z"},"papermill":{"duration":0.103137,"end_time":"2021-06-21T16:07:54.603872","exception":false,"start_time":"2021-06-21T16:07:54.500735","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BS = 32\ndm = ModelNet40DataModule(batch_size=BS, noise_function=partial(add_jitter_noise, std=0.25, clip=0.05))\n# dm.setup(num_points=NUM_POINTS, subset_ratio=0.1) # use this for prototyping as it loads faster\ndm.setup(num_points=NUM_POINTS)","metadata":{"execution":{"iopub.execute_input":"2021-06-21T16:07:54.762657Z","iopub.status.busy":"2021-06-21T16:07:54.761902Z","iopub.status.idle":"2021-06-21T16:14:30.37189Z","shell.execute_reply":"2021-06-21T16:14:30.371457Z","shell.execute_reply.started":"2021-06-21T15:53:57.423082Z"},"papermill":{"duration":395.691857,"end_time":"2021-06-21T16:14:30.372047","exception":false,"start_time":"2021-06-21T16:07:54.68019","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(dm.train_dset), len(dm.val_dset)","metadata":{"execution":{"iopub.execute_input":"2021-06-21T16:14:30.530244Z","iopub.status.busy":"2021-06-21T16:14:30.528953Z","iopub.status.idle":"2021-06-21T16:14:30.593454Z","shell.execute_reply":"2021-06-21T16:14:30.590677Z","shell.execute_reply.started":"2021-06-21T15:56:10.479301Z"},"papermill":{"duration":0.144145,"end_time":"2021-06-21T16:14:30.593646","exception":false,"start_time":"2021-06-21T16:14:30.449501","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# dm.noise_function = dm.train_dset.noise_function = dm.val_dset.noise_function = partial(add_jitter_noise, std=0.125, clip=0.05)","metadata":{"execution":{"iopub.execute_input":"2021-06-21T16:14:30.8731Z","iopub.status.busy":"2021-06-21T16:14:30.870866Z","iopub.status.idle":"2021-06-21T16:14:30.930845Z","shell.execute_reply":"2021-06-21T16:14:30.930082Z","shell.execute_reply.started":"2021-06-21T15:58:17.117741Z"},"papermill":{"duration":0.20047,"end_time":"2021-06-21T16:14:30.931036","exception":false,"start_time":"2021-06-21T16:14:30.730566","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Plot some objects to see if everything is right","metadata":{"papermill":{"duration":0.103397,"end_time":"2021-06-21T16:14:31.162504","exception":false,"start_time":"2021-06-21T16:14:31.059107","status":"completed"},"tags":[]}},{"cell_type":"code","source":"dm.train_dset.classes","metadata":{"execution":{"iopub.execute_input":"2021-06-21T16:14:31.322604Z","iopub.status.busy":"2021-06-21T16:14:31.321785Z","iopub.status.idle":"2021-06-21T16:14:31.365457Z","shell.execute_reply":"2021-06-21T16:14:31.365864Z","shell.execute_reply.started":"2021-06-21T15:56:10.633571Z"},"papermill":{"duration":0.126556,"end_time":"2021-06-21T16:14:31.366021","exception":false,"start_time":"2021-06-21T16:14:31.239465","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import plotly.express as px\n\n\nDISTINCT_LABELS = [\"object\", \"noise\"]\n\ndef pc_show(item, is_noise, category):\n    x, y, z = [item[:, i] for i in range(3)]\n    labels = [DISTINCT_LABELS[point] for point in is_noise.tolist()]\n\n    df = pd.DataFrame(dict(\n        x=x,\n        y=y,\n        z=z,\n        is_noise=labels,\n        size=[15] * len(labels),\n    ))\n    \n    print(category)\n\n    color_discrete_map = dict(zip(DISTINCT_LABELS, px.colors.sequential.Turbo))\n\n    fig = px.scatter_3d(\n        df, x=\"x\", y=\"y\", z=\"z\", color=\"is_noise\", size=\"size\",\n        opacity=0.0,\n        size_max=15,\n        color_discrete_map=color_discrete_map,\n        category_orders=dict(is_noise=DISTINCT_LABELS)\n    )\n    fig.show()\n","metadata":{"execution":{"iopub.execute_input":"2021-06-21T16:14:31.52815Z","iopub.status.busy":"2021-06-21T16:14:31.527377Z","iopub.status.idle":"2021-06-21T16:14:33.531913Z","shell.execute_reply":"2021-06-21T16:14:33.531006Z","shell.execute_reply.started":"2021-06-21T15:56:10.710663Z"},"papermill":{"duration":2.088449,"end_time":"2021-06-21T16:14:33.532077","exception":false,"start_time":"2021-06-21T16:14:31.443628","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DISTINCT_LABELS = [\"object\", \"noise\"]\n\n# We defined this because the potly version does not always work\ndef pc_show_matplotlib(item, is_noise, category, with_noise=True):\n    print(category)\n    \n    fig = plt.figure(figsize=(30, 30))\n    ax = fig.add_subplot(projection=\"3d\")\n    \n    item = item.numpy()\n    is_noise = is_noise.numpy()\n\n    markers = [\"o\"]\n    if with_noise:\n        markers.append(\"^\")\n    for i, m in enumerate(markers):\n        indices = (is_noise == i).nonzero()[0]\n        xs = item[indices, 0]\n        ys = item[indices, 1]\n        zs = item[indices, 2]\n        ax.scatter(xs, ys, zs, marker=m)\n\n    ax.set_xlabel(\"x\")\n    ax.set_ylabel(\"y\")\n    ax.set_zlabel(\"z\")\n\n    plt.show()\n","metadata":{"execution":{"iopub.execute_input":"2021-06-21T16:14:33.785112Z","iopub.status.busy":"2021-06-21T16:14:33.780235Z","iopub.status.idle":"2021-06-21T16:14:33.858561Z","shell.execute_reply":"2021-06-21T16:14:33.859873Z","shell.execute_reply.started":"2021-06-21T15:56:10.787675Z"},"papermill":{"duration":0.223626,"end_time":"2021-06-21T16:14:33.860136","exception":false,"start_time":"2021-06-21T16:14:33.63651","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"idx = rng.integers(len(dm.train_dset))\nx, y, category = dm.train_dset[idx]\ndisplay(x.shape, y.shape, category, y.sum())\npc_show_matplotlib(x, y, dm.train_dset.classes[category], True)\npc_show_matplotlib(x[y == 1], y[y == 1], dm.train_dset.classes[category], True)","metadata":{"execution":{"iopub.execute_input":"2021-06-21T16:14:34.164679Z","iopub.status.busy":"2021-06-21T16:14:34.163902Z","iopub.status.idle":"2021-06-21T16:14:35.684977Z","shell.execute_reply":"2021-06-21T16:14:35.684555Z","shell.execute_reply.started":"2021-06-21T16:02:33.835726Z"},"papermill":{"duration":1.668707,"end_time":"2021-06-21T16:14:35.685101","exception":false,"start_time":"2021-06-21T16:14:34.016394","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"threshold = 0.05\nnoise = x[y == 1]\nnoise_labels = y[y == 1]\nindices = (noise[:, None, :] - x[y == 0][None, ...]).norm(dim=-1).min(dim=-1)[0] <= threshold\nprint(indices.shape, indices.sum())\nx1 = torch.cat([x[y == 0], noise[indices]], dim=0)\ny1 = torch.cat([y[y == 0], noise_labels[indices]], dim=0)\npc_show(x1, y1, dm.train_dset.classes[category])","metadata":{"execution":{"iopub.execute_input":"2021-06-21T16:14:35.854485Z","iopub.status.busy":"2021-06-21T16:14:35.853677Z","iopub.status.idle":"2021-06-21T16:14:36.167515Z","shell.execute_reply":"2021-06-21T16:14:36.167954Z","shell.execute_reply.started":"2021-06-21T16:01:06.108048Z"},"papermill":{"duration":0.401772,"end_time":"2021-06-21T16:14:36.168118","exception":false,"start_time":"2021-06-21T16:14:35.766346","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pc_show(x, y, dm.train_dset.classes[category])","metadata":{"execution":{"iopub.execute_input":"2021-06-21T16:14:36.343483Z","iopub.status.busy":"2021-06-21T16:14:36.342708Z","iopub.status.idle":"2021-06-21T16:14:36.474804Z","shell.execute_reply":"2021-06-21T16:14:36.47527Z","shell.execute_reply.started":"2021-06-20T14:59:23.351845Z"},"papermill":{"duration":0.221924,"end_time":"2021-06-21T16:14:36.475433","exception":false,"start_time":"2021-06-21T16:14:36.253509","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x, y, cats = next(iter(dm.train_dataloader()))\nx.shape, y.shape, len(cats)","metadata":{"execution":{"iopub.execute_input":"2021-06-21T16:14:36.656473Z","iopub.status.busy":"2021-06-21T16:14:36.655678Z","iopub.status.idle":"2021-06-21T16:15:25.785746Z","shell.execute_reply":"2021-06-21T16:15:25.78644Z","shell.execute_reply.started":"2021-06-20T14:59:25.4062Z"},"papermill":{"duration":49.223444,"end_time":"2021-06-21T16:15:25.786654","exception":false,"start_time":"2021-06-21T16:14:36.56321","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{"id":"kghJ1M4NmEa0","papermill":{"duration":0.150156,"end_time":"2021-06-21T16:15:26.089191","exception":false,"start_time":"2021-06-21T16:15:25.939035","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def get_neighbours(features, idx):\n    \"\"\"\n    Input:\n        features: input points data, [B, N, C]\n        idx: neighbour index data, [B, N, K]\n    Return:\n        new_points:, indexed points data, [B, N, K, C]\n    \"\"\"\n    \n    raw_size = idx.size()\n    \n    idx = idx.reshape(raw_size[0], -1)\n    idx = idx[..., None]\n    idx = idx.expand(-1, -1, features.shape[-1])\n    \n    res = features.gather(dim=1, index=idx)\n    res = res.reshape(*raw_size, -1)\n    \n    return res","metadata":{"execution":{"iopub.execute_input":"2021-06-21T16:15:26.351892Z","iopub.status.busy":"2021-06-21T16:15:26.351085Z","iopub.status.idle":"2021-06-21T16:15:26.414607Z","shell.execute_reply":"2021-06-21T16:15:26.414141Z","shell.execute_reply.started":"2021-06-20T12:56:58.476741Z"},"papermill":{"duration":0.158556,"end_time":"2021-06-21T16:15:26.414747","exception":false,"start_time":"2021-06-21T16:15:26.256191","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class TransitionDownBlock(nn.Module):\n\n    def __init__(self, in_dims, out_dims, num_neighbours=16, sampling_ratio=0.25):\n        super().__init__()\n        \n        self.num_neighbours = num_neighbours\n        self.sampling_ratio = sampling_ratio\n        \n        self.mlp = nn.Sequential(\n            nn.Conv1d(in_dims, out_dims, kernel_size=1, bias=False), # Should be the same as Linear since dims are transposed\n            nn.BatchNorm1d(out_dims),\n            nn.ReLU(),\n        )\n\n    def forward(self, x: torch.Tensor, pos: torch.Tensor) -> torch.Tensor:\n        \n        # Flatten pos from [B, N(=num points), 3]\n        # to [B * N, 3]\n        tmp = pos.reshape((-1, pos.shape[-1]))\n        \n        # Create the tensor that will tell which point belongs to\n        # which batch element\n        batch = torch.arange(pos.shape[0]).cuda()\n        batch = torch.repeat_interleave(batch, repeats=pos.shape[1], dim=0)\n\n        # Get indices of sampled points in tmp\n        indices = fps(tmp, batch, ratio=self.sampling_ratio, random_start=True)\n        \n        # Get pos_sampled from tmp and index,\n        # shape is [B, int(N * self.sampling_ratio), 3]\n        pos_sampled = tmp[indices].reshape((pos.shape[0], -1, pos.shape[-1]))        \n        \n        \n        # KNN ------------------------------\n        # Get vector lengths using 2-norm\n        rel_dist = (pos_sampled[:, :, None, :] - pos[:, None, :, :]).norm(dim=-1)\n\n        # Get indices of k-nearest neighbours\n        num_points = x.shape[1]\n        _, neighbour_indices = rel_dist.topk(min(num_points, self.num_neighbours), largest=False)\n        \n        \n        # MLP -----------------------------\n        # Transforms input features\n        x = self.mlp(x.transpose(1, 2)).transpose(1, 2) # [B, N, out_dims]\n        \n        # Get only the neighbours\n        x_sampled = get_neighbours(x, neighbour_indices) # [B, N_sampled, k, out_dims]\n\n        \n        # MAX POOLING ---------------------\n        # Selects max value for each dimension over all neighbours\n        x_sampled = torch.max(x_sampled, dim=2)[0] # # [B, N_sampled, out_dims]\n\n        return x_sampled, pos_sampled","metadata":{"execution":{"iopub.execute_input":"2021-06-21T16:15:26.601511Z","iopub.status.busy":"2021-06-21T16:15:26.600686Z","iopub.status.idle":"2021-06-21T16:15:26.659159Z","shell.execute_reply":"2021-06-21T16:15:26.658633Z","shell.execute_reply.started":"2021-06-20T12:56:58.567073Z"},"papermill":{"duration":0.156648,"end_time":"2021-06-21T16:15:26.659288","exception":false,"start_time":"2021-06-21T16:15:26.50264","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Test\n\n# features = torch.randn((16, 16, 256))\n# pos = torch.randn((16, 16, 3))\n# lateral_pos = torch.randn((16, 64, 3))\n\n# rel_dist = (lateral_pos[:, :, None, :] - pos[:, None, :, :]).norm(dim=-1)\n# weights, neighbour_indices = rel_dist.topk(3, largest=False)\n\n# res = get_neighbours(features, neighbour_indices)\n# res.shape","metadata":{"execution":{"iopub.execute_input":"2021-06-21T16:15:26.845982Z","iopub.status.busy":"2021-06-21T16:15:26.840302Z","iopub.status.idle":"2021-06-21T16:15:26.897513Z","shell.execute_reply":"2021-06-21T16:15:26.896993Z","shell.execute_reply.started":"2021-06-20T12:56:58.654345Z"},"papermill":{"duration":0.149682,"end_time":"2021-06-21T16:15:26.897634","exception":false,"start_time":"2021-06-21T16:15:26.747952","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Test\n\n# features = torch.arange(2*8*2).reshape(2, 8, 2)\n# features\n# pos = torch.randn((2, 8, 3))\n# lateral_pos = torch.randn((2, 32, 3))\n\n# print(features[0])\n# rel_dist = (lateral_pos[:, :, None, :] - pos[:, None, :, :]).norm(dim=-1)\n# weights, neighbour_indices = rel_dist.topk(3, largest=False)\n# print(neighbour_indices[0, :3])\n\n# res = get_neighbours(features, neighbour_indices)\n# res.shape, res[0, :3]","metadata":{"execution":{"iopub.execute_input":"2021-06-21T16:15:27.080867Z","iopub.status.busy":"2021-06-21T16:15:27.080047Z","iopub.status.idle":"2021-06-21T16:15:27.136149Z","shell.execute_reply":"2021-06-21T16:15:27.135706Z","shell.execute_reply.started":"2021-06-20T12:56:58.732184Z"},"papermill":{"duration":0.148727,"end_time":"2021-06-21T16:15:27.136274","exception":false,"start_time":"2021-06-21T16:15:26.987547","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class TransitionUpBlock(nn.Module):\n\n    def __init__(self, in_dims, out_dims):\n        super().__init__()\n\n        self.up_mlp = nn.Sequential(\n            nn.Conv1d(in_dims, out_dims, kernel_size=1, bias=False),\n            nn.BatchNorm1d(out_dims),\n            nn.ReLU()\n        )\n        self.lateral_mlp = nn.Sequential(\n            nn.Conv1d(out_dims, out_dims, kernel_size=1, bias=False),\n            nn.BatchNorm1d(out_dims),\n            nn.ReLU()\n        )\n\n    def forward(self, features, pos, lateral_features, lateral_pos):\n        \"\"\"\n            features: (B, N, in_channels) torch.Tensor\n            pos: (B, N, 3) torch.Tensor\n            lateral_features: (B, M, out_channels) torch.Tensor\n            lateral_pos: (B, M, 3) torch.Tensor\n        Note that N is smaller than M because this module upsamples features.\n        \"\"\"\n        \n        features = self.up_mlp(features.transpose(1, 2)).transpose(1, 2)\n        \n        # Find three nearest neighbours of lateral_pos in pos\n        rel_dist = (lateral_pos[:, :, None, :] - pos[:, None, :, :]).norm(dim=-1)\n        weights, neighbour_indices = rel_dist.topk(3, largest=False)\n        \n        # Interpolation weights\n        weights = 1.0 / (weights + 1e-8)\n        weights = weights / torch.sum(weights, dim=2, keepdim=True) # [B, M, 3]\n        \n        # Get triplets of vectors to interpolate from\n        interpolated_features = get_neighbours(features, neighbour_indices) # [B, M, 3, C]\n        # Do interpolation using weights from above\n        interpolated_features = torch.sum(interpolated_features * weights[..., None], dim=-2)\n        \n        lateral_features = self.lateral_mlp(lateral_features.transpose(1, 2)).transpose(1, 2)\n        \n        # Add interpolated features to features from before\n        out = interpolated_features + lateral_features\n        \n        return out, lateral_pos","metadata":{"execution":{"iopub.execute_input":"2021-06-21T16:15:27.323409Z","iopub.status.busy":"2021-06-21T16:15:27.322593Z","iopub.status.idle":"2021-06-21T16:15:27.37978Z","shell.execute_reply":"2021-06-21T16:15:27.379347Z","shell.execute_reply.started":"2021-06-20T12:56:58.808463Z"},"papermill":{"duration":0.154875,"end_time":"2021-06-21T16:15:27.379905","exception":false,"start_time":"2021-06-21T16:15:27.22503","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Test\n\n# features = torch.randn((16, 16, 256))\n# pos = torch.randn((16, 16, 3))\n# lateral_features = torch.randn((16, 64, 128))\n# lateral_pos = torch.randn((16, 64, 3))\n\n# up = TransitionUpBlock(in_channels=256, out_channels=128)\n\n# with torch.no_grad():\n#     feat, pos = up(features, pos, lateral_features, lateral_pos)\n#     print(feat.shape)\n#     print(pos.shape)","metadata":{"execution":{"iopub.execute_input":"2021-06-21T16:15:27.564095Z","iopub.status.busy":"2021-06-21T16:15:27.563293Z","iopub.status.idle":"2021-06-21T16:15:27.619118Z","shell.execute_reply":"2021-06-21T16:15:27.61869Z","shell.execute_reply.started":"2021-06-20T12:56:58.895331Z"},"papermill":{"duration":0.149164,"end_time":"2021-06-21T16:15:27.619256","exception":false,"start_time":"2021-06-21T16:15:27.470092","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class PointTransformerLayer(nn.Module):\n    def __init__(\n        self,\n        dim,\n        num_neighbors,\n        pos_mlp_hidden_dim=64,\n        attn_mlp_hidden_mult=4, # This comes from initial Transformer paper\n        dropout=0,\n    ):\n        super().__init__()\n        self.num_neighbors = num_neighbors\n\n        self.to_queries = nn.Linear(dim, dim, bias=False) # phi\n        self.to_keys = nn.Linear(dim, dim, bias=False) # psi\n        self.to_values = nn.Linear(dim, dim, bias=False) # alpha\n\n        # theta\n        self.pos_mlp = nn.Sequential(\n            nn.Linear(3, pos_mlp_hidden_dim),\n            nn.ReLU(),\n            nn.Linear(pos_mlp_hidden_dim, dim)\n        )\n        \n        # gamma\n        self.to_attn_weights = nn.Sequential(\n            nn.Linear(dim, dim * attn_mlp_hidden_mult),\n            nn.ReLU(),\n            nn.Linear(dim * attn_mlp_hidden_mult, dim),\n        )\n        \n        self.drop = nn.Dropout(dropout)\n\n    def forward(self, x: torch.Tensor, pos: torch.Tensor) -> torch.Tensor:\n        num_points, num_neighbors = x.shape[1], self.num_neighbors\n        \n        # get nearest neighbour indices\n        rel_dist = (pos[:, :, None, :] - pos[:, None, :, :]).norm(dim=-1)\n        _, neighbour_indices = rel_dist.topk(min(num_neighbors, num_points), largest=False)\n\n        # get queries, keys, values,\n        # immediately leaving only the neighbouring points for k and v\n        q = self.to_queries(x)\n        k = get_neighbours(self.to_keys(x), neighbour_indices)\n        v = get_neighbours(self.to_values(x), neighbour_indices)\n\n        # use subtraction relation between queries and keys\n        qk_rel = q[:, :, None, :] - k\n\n        # calculate position embeddings\n        rel_pos_emb = self.pos_mlp(pos[:, :, None, :] - get_neighbours(pos, neighbour_indices))\n        rel_pos_emb = self.drop(rel_pos_emb)\n        \n        # add relative positional embeddings to values\n        v += rel_pos_emb\n\n        # use attention weights mlp, making sure to add relative positional embedding first\n        rel_pos_emb = self.to_attn_weights(qk_rel + rel_pos_emb)\n\n        # attention weights\n        rel_pos_emb = rel_pos_emb.softmax(dim=-2)\n\n        # aggregate\n        agg = torch.sum(torch.mul(rel_pos_emb, v), dim=-2)\n        \n        return agg","metadata":{"execution":{"iopub.execute_input":"2021-06-21T16:15:27.811652Z","iopub.status.busy":"2021-06-21T16:15:27.810807Z","iopub.status.idle":"2021-06-21T16:15:27.868055Z","shell.execute_reply":"2021-06-21T16:15:27.86758Z","shell.execute_reply.started":"2021-06-20T12:56:58.973258Z"},"papermill":{"duration":0.1613,"end_time":"2021-06-21T16:15:27.868204","exception":false,"start_time":"2021-06-21T16:15:27.706904","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class PointTransformerBlock(nn.Module):\n    def __init__(self, dim, hidden_dim, pos_mlp_hidden_dim=64, attn_mlp_hidden_mult=4, dropouts=None, num_neighbours=None):\n        super().__init__()\n        \n        self.fc_in = nn.Linear(dim, hidden_dim)\n        self.point_transformer_layer = PointTransformerLayer(\n            dim=hidden_dim,\n            num_neighbors=num_neighbours,\n            pos_mlp_hidden_dim=pos_mlp_hidden_dim,\n            attn_mlp_hidden_mult=attn_mlp_hidden_mult, # This comes from initial Transformer paper\n            dropout=dropouts[0] if dropouts else 0,\n        )\n        self.fc_out = nn.Linear(hidden_dim, dim)\n        \n        self.drop = nn.Dropout(dropouts[1] if dropouts else 0)\n    \n    def forward(self, x: torch.Tensor, pos: torch.Tensor) -> torch.Tensor:\n        out = self.fc_in(x)\n        \n        out = self.point_transformer_layer(out, pos)\n        \n        out = self.fc_out(out)\n        \n        out = self.drop(out)\n        \n        # Residual\n        out = out + x\n        \n        return out","metadata":{"execution":{"iopub.execute_input":"2021-06-21T16:15:28.054327Z","iopub.status.busy":"2021-06-21T16:15:28.053478Z","iopub.status.idle":"2021-06-21T16:15:28.113131Z","shell.execute_reply":"2021-06-21T16:15:28.112655Z","shell.execute_reply.started":"2021-06-20T12:56:59.060805Z"},"papermill":{"duration":0.155685,"end_time":"2021-06-21T16:15:28.113269","exception":false,"start_time":"2021-06-21T16:15:27.957584","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Test\n\n# from itertools import tee\n\n# def pairwise(iterable):\n#     \"s -> (s0,s1), (s1,s2), (s2, s3), ...\"\n#     a, b = tee(iterable)\n#     next(b, None)\n#     return list(zip(a, b))","metadata":{"papermill":{"duration":0.149826,"end_time":"2021-06-21T16:15:28.352323","exception":false,"start_time":"2021-06-21T16:15:28.202497","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-02-04T11:59:03.187255Z","iopub.execute_input":"2022-02-04T11:59:03.187697Z","iopub.status.idle":"2022-02-04T11:59:03.193155Z","shell.execute_reply.started":"2022-02-04T11:59:03.187610Z","shell.execute_reply":"2022-02-04T11:59:03.191965Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"class PointTransformerSegmentator(nn.Module):\n    def __init__(self, layer_config, num_neighbours=16, sampling_ratio=0.25, dropouts=None):\n        super().__init__()\n        assert dropouts is None or len(dropouts) == 3\n        \n        in_dims, *inner_dims, out_dims = layer_config\n        encoder_dims = pairwise(inner_dims)\n        decoder_dims = pairwise(inner_dims[::-1])\n        \n        self.encoder_transitions = nn.ModuleList([\n            nn.Sequential(\n                nn.Linear(in_dims, inner_dims[0]),\n                nn.ReLU(),\n                nn.Linear(inner_dims[0], inner_dims[0]),\n            ),\n        ] + [\n            TransitionDownBlock(\n                in_dims=in_dims,\n                out_dims=out_dims,\n                num_neighbours=num_neighbours,\n                sampling_ratio=sampling_ratio,\n            )\n            for in_dims, out_dims in encoder_dims\n        ])\n        self.encoder_transformers = nn.ModuleList([\n            PointTransformerBlock(\n                dim=dims,\n                hidden_dim=dims,\n                pos_mlp_hidden_dim=dims,\n                attn_mlp_hidden_mult=4,\n                num_neighbours=num_neighbours,\n                dropouts=dropouts[:-1] if dropouts else None,\n            )\n            for dims in inner_dims\n        ])\n        \n        self.decoder_transitions = nn.ModuleList([\n            nn.Linear(inner_dims[-1], inner_dims[-1]),\n        ] + [\n            TransitionUpBlock(\n                in_dims=in_dims,\n                out_dims=out_dims,\n            )\n            for in_dims, out_dims in decoder_dims\n        ])\n        self.decoder_transformers = nn.ModuleList([\n            PointTransformerBlock(\n                dim=dims,\n                hidden_dim=dims,\n                pos_mlp_hidden_dim=dims,\n                attn_mlp_hidden_mult=4,\n                num_neighbours=num_neighbours,\n                dropouts=dropouts[:-1] if dropouts else None,\n            )\n            for dims in inner_dims[::-1]\n        ])\n        \n        self.drop = nn.Dropout(dropouts[-1] if dropouts else 0)\n        \n        self.fc_out = nn.Sequential(\n            nn.Linear(inner_dims[0], inner_dims[0]),\n            nn.ReLU(),\n            nn.Linear(inner_dims[0], out_dims),\n        )\n    \n    def forward(self, pos: torch.Tensor) -> torch.Tensor:\n        lateral_features = []\n        lateral_pos = []\n\n        for i, (trans_down, transformer) in enumerate(zip(self.encoder_transitions, self.encoder_transformers)):\n            if i == 0:\n                features = trans_down(pos)\n                features = transformer(features, pos)\n            else:\n                features, pos = trans_down(features, pos)\n                features = transformer(features, pos)\n\n            if i < len(self.encoder_transitions) - 1:\n                lateral_features.append(features)\n                lateral_pos.append(pos)\n\n        for i, (trans_up, transformer) in enumerate(zip(self.decoder_transitions, self.decoder_transformers)):\n            if i == 0:\n                features = trans_up(features)\n                features = transformer(features, pos)\n            else:\n                features, pos = trans_up(features, pos, lateral_features[-i], lateral_pos[-i])\n                features = transformer(features, pos)\n\n        out = self.drop(features)\n\n        out = self.fc_out(out)\n        \n        return out","metadata":{"execution":{"iopub.execute_input":"2021-06-21T16:15:28.543684Z","iopub.status.busy":"2021-06-21T16:15:28.542837Z","iopub.status.idle":"2021-06-21T16:15:28.601056Z","shell.execute_reply":"2021-06-21T16:15:28.601442Z","shell.execute_reply.started":"2021-06-20T12:56:59.22491Z"},"papermill":{"duration":0.161294,"end_time":"2021-06-21T16:15:28.601595","exception":false,"start_time":"2021-06-21T16:15:28.440301","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training","metadata":{"id":"XbK48S6wmEa4","papermill":{"duration":0.087039,"end_time":"2021-06-21T16:15:28.776607","exception":false,"start_time":"2021-06-21T16:15:28.689568","status":"completed"},"tags":[]}},{"cell_type":"code","source":"from dataclasses import dataclass\n\n@dataclass\nclass CMCounts:\n    tp: int = 0\n    fp: int = 0\n    fn: int = 0\n    tn: int = 0\n    \n    # two tensors\n    @classmethod\n    def from_tensors(cls, target, preds):\n        tp, fp, fn, tn = torch.dstack((\n            preds & target > 0,\n            preds > target,\n            preds < target,\n            preds | target == 0,\n        )).sum((0, 1))\n        return cls(*[x.item() for x in [tp, fp, fn, tn]])\n        \n        \n    @property\n    def f1(self):\n        return self.tp / (self.tp + 0.5 * (self.fp + self.fn))\n    \n    @property\n    def f2(self):\n        return self.f_beta(2)\n    \n    def f_beta(self, beta):\n        return (1 + beta ** 2) * self.tp / ((1 + beta ** 2) * self.tp + (beta ** 2) * self.fn + self.fp)\n    \n    @property\n    def accuracy(self):\n        return (self.tp + self.tn) / (self.tp + self.fp + self.fn + self.tn)\n    \n    def __add__(self, other):\n        return CMCounts(\n            tp=self.tp + other.tp,\n            fp=self.fp + other.fp,\n            fn=self.fn + other.fn,\n            tn=self.tn + other.tn,\n        )\n    \n    def __radd__(self, other):\n        return self if other == 0 else self + other","metadata":{"execution":{"iopub.execute_input":"2021-06-21T16:15:28.961636Z","iopub.status.busy":"2021-06-21T16:15:28.960804Z","iopub.status.idle":"2021-06-21T16:15:29.019316Z","shell.execute_reply":"2021-06-21T16:15:29.018828Z","shell.execute_reply.started":"2021-06-20T12:58:25.029685Z"},"papermill":{"duration":0.155373,"end_time":"2021-06-21T16:15:29.01945","exception":false,"start_time":"2021-06-21T16:15:28.864077","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class SegmentationTask(pl.LightningModule):\n    def __init__(self, model, max_lr, epochs, steps_per_epoch, num_classes=2):\n        super().__init__()\n        self.save_hyperparameters(\"max_lr\", \"epochs\")\n        self.steps_per_epoch = steps_per_epoch\n        self.model = model\n        self.loss = nn.BCEWithLogitsLoss(reduction=\"mean\")\n        \n    def forward(self, x):\n        return self.model(x)\n\n\n    def _shared_step(self, batch, prefix):\n        x, y, _ = batch\n        logits = self.model(x).squeeze()\n        loss = self.loss(logits, y.float())\n        \n        y_preds = (logits >= 0.0).long() # since we do not call sigmoid\n        \n        cm_counts = CMCounts.from_tensors(y.flatten(), y_preds.flatten())\n\n        self.log(f\"{prefix}_loss\", loss, on_step=False, on_epoch=True)\n\n        return { \"loss\": loss, \"cm_counts\": cm_counts }\n    \n    # TODO: this is hard-coded, should be automated\n    def on_train_start(self):\n        self.logger.log_hyperparams({\n            \"bs\": BS, \"num_points\": NUM_POINTS,\n            \"max_lr\": self.hparams.max_lr, \"epochs\": self.hparams.epochs,\n            \"optimizer\": \"AdamW(wd=1e-2)\", \"scheduler\": \"OneCycleLR\",\n        })\n    \n    \n    def training_step(self, batch, batch_idx):\n        return self._shared_step(batch, \"train\")\n\n\n    def training_epoch_end(self, outs):\n        cm_count_total = sum(map(lambda x: x[\"cm_counts\"], outs))\n        self.log(\"train_f1\", cm_count_total.f1)\n        self.log(\"train_f2\", cm_count_total.f2)\n\n\n    def validation_step(self, batch, batch_idx):\n        return self._shared_step(batch, \"valid\")\n\n    \n    def validation_epoch_end(self, outs):\n        cm_count_total = sum(map(lambda x: x[\"cm_counts\"], outs))\n        self.log(\"valid_f1\", cm_count_total.f1)\n        self.log(\"valid_f2\", cm_count_total.f2)\n\n\n    def configure_optimizers(self):\n        optimizer = optim.AdamW(self.model.parameters(), weight_decay=1e-2)\n        lr_scheduler = optim.lr_scheduler.OneCycleLR(\n            optimizer, max_lr=self.hparams.max_lr,\n            steps_per_epoch=self.steps_per_epoch,\n            epochs=self.hparams.epochs\n        )\n        lr_dict = { \"scheduler\": lr_scheduler, \"interval\": \"step\" }\n        return [optimizer], [lr_dict]","metadata":{"execution":{"iopub.execute_input":"2021-06-21T16:15:29.210147Z","iopub.status.busy":"2021-06-21T16:15:29.209292Z","iopub.status.idle":"2021-06-21T16:15:29.267165Z","shell.execute_reply":"2021-06-21T16:15:29.266694Z","shell.execute_reply.started":"2021-06-20T12:58:25.119031Z"},"papermill":{"duration":0.158624,"end_time":"2021-06-21T16:15:29.267303","exception":false,"start_time":"2021-06-21T16:15:29.108679","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"layer_config = [3, 32, 64, 128, 256, 512, 1]\n\nmodel = PointTransformerSegmentator(\n    layer_config=layer_config,\n    num_neighbours=16,\n    sampling_ratio=0.25,\n    dropouts=[0.0, 0.0, 0.0]\n)\n\nEPOCHS = 50\nLR = 1e-3\n\nsegmentator = SegmentationTask(\n    model,\n    max_lr=LR,\n    epochs=EPOCHS,\n    steps_per_epoch=len(dm.train_dataloader()),\n    num_classes=1\n)","metadata":{"execution":{"iopub.execute_input":"2021-06-21T16:15:29.449033Z","iopub.status.busy":"2021-06-21T16:15:29.448252Z","iopub.status.idle":"2021-06-21T16:15:29.591903Z","shell.execute_reply":"2021-06-21T16:15:29.591463Z","shell.execute_reply.started":"2021-06-20T12:58:25.208555Z"},"papermill":{"duration":0.236719,"end_time":"2021-06-21T16:15:29.592046","exception":false,"start_time":"2021-06-21T16:15:29.355327","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from datetime import datetime\nfrom pytz import timezone\n\n# Make sure to change wandb parameters or get rid of it altogether\nwandb_logger = pl.loggers.WandbLogger(\n    project=\"project-name\",\n    entity=\"company-name\",\n    name=str(datetime.now(tz=timezone(\"Continent/City\")))\n)\n# Select path where you want to log to\ntrainer = pl.Trainer(gpus=1, max_epochs=EPOCHS, logger=[pl.loggers.CSVLogger(\"path/to/logs\"), wandb_logger])","metadata":{"execution":{"iopub.execute_input":"2021-06-21T16:15:29.774245Z","iopub.status.busy":"2021-06-21T16:15:29.773403Z","iopub.status.idle":"2021-06-21T16:15:29.855531Z","shell.execute_reply":"2021-06-21T16:15:29.855015Z","shell.execute_reply.started":"2021-06-20T12:58:25.405775Z"},"papermill":{"duration":0.175965,"end_time":"2021-06-21T16:15:29.855653","exception":false,"start_time":"2021-06-21T16:15:29.679688","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lr_finder = trainer.tuner.lr_find(segmentator, datamodule=dm, min_lr=1e-6, max_lr=1e-1)\nfig = lr_finder.plot(suggest=True)\nfig.show()","metadata":{"execution":{"iopub.execute_input":"2021-06-21T16:15:30.038094Z","iopub.status.busy":"2021-06-21T16:15:30.037297Z","iopub.status.idle":"2021-06-21T16:41:38.736151Z","shell.execute_reply":"2021-06-21T16:41:38.73661Z","shell.execute_reply.started":"2021-06-20T12:58:25.524253Z"},"papermill":{"duration":1568.791856,"end_time":"2021-06-21T16:41:38.73678","exception":false,"start_time":"2021-06-21T16:15:29.944924","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# classifier.hparams.lr = lr_finder.suggestion() # use if you want the lr to be selected automatically\nlr_finder.suggestion()","metadata":{"execution":{"iopub.execute_input":"2021-06-21T16:41:39.04285Z","iopub.status.busy":"2021-06-21T16:41:39.04206Z","iopub.status.idle":"2021-06-21T16:41:39.127629Z","shell.execute_reply":"2021-06-21T16:41:39.126752Z","shell.execute_reply.started":"2021-06-20T12:59:28.021781Z"},"papermill":{"duration":0.244539,"end_time":"2021-06-21T16:41:39.12783","exception":false,"start_time":"2021-06-21T16:41:38.883291","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer.fit(segmentator, datamodule=dm)","metadata":{"execution":{"iopub.execute_input":"2021-06-21T16:41:39.315453Z","iopub.status.busy":"2021-06-21T16:41:39.314668Z","iopub.status.idle":"2021-06-21T18:55:33.003201Z","shell.execute_reply":"2021-06-21T18:55:33.004279Z","shell.execute_reply.started":"2021-06-20T12:59:28.112279Z"},"papermill":{"duration":8033.784191,"end_time":"2021-06-21T18:55:33.00452","exception":false,"start_time":"2021-06-21T16:41:39.220329","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Put weight save path here\ntrainer.save_checkpoint(\"path/to/weights.ckpt\")","metadata":{"execution":{"iopub.execute_input":"2021-06-21T18:55:33.501396Z","iopub.status.busy":"2021-06-21T18:55:33.500576Z","iopub.status.idle":"2021-06-21T18:55:34.54443Z","shell.execute_reply":"2021-06-21T18:55:34.545359Z","shell.execute_reply.started":"2021-06-20T13:00:49.317728Z"},"papermill":{"duration":1.310153,"end_time":"2021-06-21T18:55:34.545567","exception":false,"start_time":"2021-06-21T18:55:33.235414","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import wandb\nwandb.finish() # Do not forget to finish wandb session","metadata":{"execution":{"iopub.execute_input":"2021-06-21T18:55:35.046364Z","iopub.status.busy":"2021-06-21T18:55:35.045536Z","iopub.status.idle":"2021-06-21T18:55:38.697029Z","shell.execute_reply":"2021-06-21T18:55:38.696273Z","shell.execute_reply.started":"2021-06-20T13:00:49.779867Z"},"papermill":{"duration":3.880049,"end_time":"2021-06-21T18:55:38.697192","exception":false,"start_time":"2021-06-21T18:55:34.817143","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Evaluation","metadata":{"id":"6SSHfjLCd4ls","papermill":{"duration":0.224407,"end_time":"2021-06-21T18:55:39.129519","exception":false,"start_time":"2021-06-21T18:55:38.905112","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def plot_metric(data, metric_label, is_log_scale=False, quiet=False):\n    if not quiet:\n        print(f\"train_{metric_label}: {logs[f'train_{metric_label}'].dropna().values[-1]:.2f}\")\n        print(f\"valid_{metric_label}: {logs[f'valid_{metric_label}'].dropna().values[-1]:.2f}\")\n\n    sns.lineplot(data=data, x=\"epoch\", y=f\"train_{metric_label}\", color=\"red\", label=\"train\")\n    sns.lineplot(data=data, x=\"epoch\", y=f\"valid_{metric_label}\", color=\"blue\", label=\"valid\")\n    if is_log_scale:\n        plt.yscale(\"log\")\n    plt.title(f\"{'log ' if is_log_scale else ''}{metric_label}\")\n    plt.legend()\n    plt.show()","metadata":{"execution":{"iopub.execute_input":"2021-06-21T18:55:39.645807Z","iopub.status.busy":"2021-06-21T18:55:39.644823Z","iopub.status.idle":"2021-06-21T18:55:39.869087Z","shell.execute_reply":"2021-06-21T18:55:39.869719Z","shell.execute_reply.started":"2021-06-20T13:00:54.062796Z"},"papermill":{"duration":0.471638,"end_time":"2021-06-21T18:55:39.869912","exception":false,"start_time":"2021-06-21T18:55:39.398274","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Put path to logs here\n# It only worked for us if we added default at the end,\n# so make sure to check if that is the case for you\nLOG_PATH = Path(\"path/to/logs/default\")\nlog_file = sorted(list(LOG_PATH.glob(\"**/*.csv\")), key=lambda x: int(x.parent.stem.split(\"_\")[1]))[-1]\nprint(log_file)\n\nlogs = pd.read_csv(log_file)\ndisplay(logs)\n\nplot_metric(logs, \"loss\")\nplot_metric(logs, \"loss\", is_log_scale=True, quiet=True)\nplot_metric(logs, \"f1\")\nplot_metric(logs, \"f2\")","metadata":{"execution":{"iopub.execute_input":"2021-06-21T18:55:40.532951Z","iopub.status.busy":"2021-06-21T18:55:40.532217Z","iopub.status.idle":"2021-06-21T18:55:43.051104Z","shell.execute_reply":"2021-06-21T18:55:43.052158Z","shell.execute_reply.started":"2021-06-20T13:00:54.139949Z"},"papermill":{"duration":2.850865,"end_time":"2021-06-21T18:55:43.052362","exception":false,"start_time":"2021-06-21T18:55:40.201497","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from collections import defaultdict\n\ndef evaluate(model, dl):\n\n    model.cuda()\n    model.eval()\n    \n    instances = dl.dataset.classes\n    cm_count_dict = defaultdict(CMCounts)\n    with torch.no_grad():\n        for x, y, cats in tqdm(dl, total=len(dl)):\n            x, y = x.cuda(), y.cuda()\n            logits = model(x).squeeze()\n            \n            segm_preds = (logits >= 0.0).long() # since we do not call sigmoid\n            \n            cats = np.array(cats)\n            for i, cat in enumerate(instances):\n                mask = cats == i\n                cat_ys = y[mask].flatten()\n                cat_y_preds = segm_preds[mask].flatten()\n                cm_count_new = CMCounts.from_tensors(y[mask].flatten(), segm_preds[mask].flatten())\n                cm_count_dict[cat] += cm_count_new\n                \n    cm_count_total = sum([value for _, value in cm_count_dict.items()])\n    print(f\"F1: {cm_count_total.f1}\")\n    print(f\"F2: {cm_count_total.f2}\")\n    print(f\"Acc: {cm_count_total.accuracy}\")\n    \n    dict_for_df = {\n        \"tp%\": { key: value.tp / (value.tp + value.fp + value.fn + value.tn) for key, value in cm_count_dict.items() },\n        \"fp%\": { key: value.fp / (value.tp + value.fp + value.fn + value.tn) for key, value in cm_count_dict.items() },\n        \"fn%\": { key: value.fn / (value.tp + value.fp + value.fn + value.tn) for key, value in cm_count_dict.items() },\n        \"tn%\": { key: value.tn / (value.tp + value.fp + value.fn + value.tn) for key, value in cm_count_dict.items() },\n        \"f1\": { key: value.f1 for key, value in cm_count_dict.items() },\n        \"acc\": { key: value.accuracy for key, value in cm_count_dict.items() },\n    }\n    df = pd.DataFrame(dict_for_df)\n    display(df)\n    ax = df.plot.bar(y=\"f1\", rot=90)\n    ax = df.plot.bar(y=\"acc\", rot=90)","metadata":{"execution":{"iopub.execute_input":"2021-06-21T18:55:43.594221Z","iopub.status.busy":"2021-06-21T18:55:43.593439Z","iopub.status.idle":"2021-06-21T18:55:43.805645Z","shell.execute_reply":"2021-06-21T18:55:43.804766Z","shell.execute_reply.started":"2021-06-20T13:09:20.877976Z"},"papermill":{"duration":0.485794,"end_time":"2021-06-21T18:55:43.805804","exception":false,"start_time":"2021-06-21T18:55:43.32001","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"evaluate(segmentator, dm.train_dataloader())","metadata":{"execution":{"iopub.execute_input":"2021-06-21T18:55:44.52962Z","iopub.status.busy":"2021-06-21T18:55:44.528871Z","iopub.status.idle":"2021-06-21T19:13:23.077261Z","shell.execute_reply":"2021-06-21T19:13:23.078532Z","shell.execute_reply.started":"2021-06-20T13:09:21.013949Z"},"papermill":{"duration":1058.872886,"end_time":"2021-06-21T19:13:23.078757","exception":false,"start_time":"2021-06-21T18:55:44.205871","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"evaluate(segmentator, dm.val_dataloader())","metadata":{"execution":{"iopub.execute_input":"2021-06-21T19:13:23.572828Z","iopub.status.busy":"2021-06-21T19:13:23.572117Z","iopub.status.idle":"2021-06-21T19:33:03.623856Z","shell.execute_reply":"2021-06-21T19:33:03.628679Z","shell.execute_reply.started":"2021-06-20T13:09:39.681952Z"},"papermill":{"duration":1180.319378,"end_time":"2021-06-21T19:33:03.628927","exception":false,"start_time":"2021-06-21T19:13:23.309549","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Plotting","metadata":{"papermill":{"duration":0.331424,"end_time":"2021-06-21T19:33:04.34865","exception":false,"start_time":"2021-06-21T19:33:04.017226","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import plotly.express as px\n\ndef pc_show_ground_truth_vs_prediction(item, ground_truth, prediction, category):\n    x, y, z = [item[:, i] for i in range(3)]\n    labels = [DISTINCT_LABELS[point.item()] for point in ground_truth]\n    labels_pred = [DISTINCT_LABELS[point.item()] for point in prediction]\n\n    df = pd.DataFrame(dict(\n        x=x,\n        y=y,\n        z=z,\n        ground_truth=labels,\n        predicted=labels_pred,\n        size=[15] * len(labels),\n    ))\n    \n    print(category)\n\n    color_discrete_map = dict(zip(DISTINCT_LABELS, [\"blue\", \"red\"]))\n\n    fig = px.scatter_3d(\n        df, x=\"x\", y=\"y\", z=\"z\", color=\"ground_truth\", size=\"size\",\n        opacity=0.0,\n        size_max=15,\n        color_discrete_map=color_discrete_map,\n        category_orders=dict(is_noise=DISTINCT_LABELS)\n    )\n    fig.show()\n\n    fig = px.scatter_3d(\n        df, x=\"x\", y=\"y\", z=\"z\", color=\"predicted\", size=\"size\",\n        opacity=0.0,\n        size_max=15,\n        color_discrete_map=color_discrete_map,\n        category_orders=dict(is_noise=DISTINCT_LABELS)\n    )\n    fig.show()","metadata":{"execution":{"iopub.execute_input":"2021-06-21T19:33:04.764226Z","iopub.status.busy":"2021-06-21T19:33:04.76349Z","iopub.status.idle":"2021-06-21T19:33:04.859124Z","shell.execute_reply":"2021-06-21T19:33:04.860091Z","shell.execute_reply.started":"2021-06-20T13:16:16.420133Z"},"papermill":{"duration":0.26307,"end_time":"2021-06-21T19:33:04.860281","exception":false,"start_time":"2021-06-21T19:33:04.597211","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def pc_show_error(item, ground_truth, prediction, category):\n    x, y, z = [item[:, i] for i in range(3)]\n\n    are_agreeing = ground_truth == prediction\n    lbls = [\"Agree, was object\", \"Agree, was noise\", \"Disagree, was object\", \"Disagree, was noise\"]\n    labels = []\n    for i, point in enumerate(ground_truth):\n        if are_agreeing[i]:\n            labels.append(\"Agree, was object\" if ground_truth[i] == 0 else \"Agree, was noise\")\n        else:\n            labels.append(\"Disagree, was object\" if ground_truth[i] == 0 else \"Disagree, was noise\")\n\n    df = pd.DataFrame(dict(\n        x=x,\n        y=y,\n        z=z,\n        predictions=labels,\n        size=[15] * len(labels),\n    ))\n    \n    print(category)\n\n    color_discrete_map = dict(zip(DISTINCT_LABELS, [\"green\", \"blue\", \"red\", \"yellow\"]))\n\n    fig = px.scatter_3d(\n        df, x=\"x\", y=\"y\", z=\"z\", color=\"predictions\", size=\"size\",\n        opacity=0.0,\n        size_max=15,\n        color_discrete_map=color_discrete_map,\n        category_orders=dict(is_noise=DISTINCT_LABELS)\n    )\n    fig.show()\n    \n\ndef pc_show_error_matplotlib(item, ground_truth, prediction, category):\n    print(category)\n    \n    fig = plt.figure(figsize=(30, 30))\n    ax = fig.add_subplot(projection=\"3d\")\n    \n    x, y, z = [item[:, i] for i in range(3)]\n    \n    are_agreeing = ground_truth == prediction\n    lbls = [\"Agree, was object\", \"Agree, was noise\", \"Disagree, was object\", \"Disagree, was noise\"]\n    labels = []\n    for i, point in enumerate(ground_truth):\n        if are_agreeing[i]:\n            labels.append(\"Agree, was object\" if ground_truth[i] == 0 else \"Agree, was noise\")\n        else:\n            labels.append(\"Disagree, was object\" if ground_truth[i] == 0 else \"Disagree, was noise\")\n\n    labels = np.array(labels)\n    colours = [\"green\", \"blue\", \"red\", \"orange\"]\n    for i, c in enumerate(colours):\n        indices = (labels == lbls[i]).nonzero()[0]\n        xs = item[indices, 0]\n        ys = item[indices, 1]\n        zs = item[indices, 2]\n        ax.scatter(xs, ys, zs, color=c, s=50, label=lbls[i])\n    \n    ax.set_xlabel(\"x\")\n    ax.set_ylabel(\"y\")\n    ax.set_zlabel(\"z\")\n    ax.legend()\n\n    plt.show()","metadata":{"execution":{"iopub.execute_input":"2021-06-21T19:33:05.252022Z","iopub.status.busy":"2021-06-21T19:33:05.25127Z","iopub.status.idle":"2021-06-21T19:33:05.366788Z","shell.execute_reply":"2021-06-21T19:33:05.36735Z","shell.execute_reply.started":"2021-06-20T13:29:28.23854Z"},"papermill":{"duration":0.350643,"end_time":"2021-06-21T19:33:05.367565","exception":false,"start_time":"2021-06-21T19:33:05.016922","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"instances = dm.val_dset.classes; instances","metadata":{"execution":{"iopub.execute_input":"2021-06-21T19:33:06.601078Z","iopub.status.busy":"2021-06-21T19:33:06.600301Z","iopub.status.idle":"2021-06-21T19:33:06.755531Z","shell.execute_reply":"2021-06-21T19:33:06.756071Z","shell.execute_reply.started":"2021-06-20T13:29:29.599719Z"},"papermill":{"duration":0.429669,"end_time":"2021-06-21T19:33:06.756259","exception":false,"start_time":"2021-06-21T19:33:06.32659","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ins_identifier = instances.index(\"airplane\")\nmodels = [obj for obj in dm.val_dset if obj[2] == ins_identifier]\nlen(models)","metadata":{"execution":{"iopub.execute_input":"2021-06-21T19:33:07.358828Z","iopub.status.busy":"2021-06-21T19:33:07.358075Z","iopub.status.idle":"2021-06-21T19:51:44.475758Z","shell.execute_reply":"2021-06-21T19:51:44.47625Z","shell.execute_reply.started":"2021-06-20T13:29:30.255473Z"},"papermill":{"duration":1117.389784,"end_time":"2021-06-21T19:51:44.476422","exception":false,"start_time":"2021-06-21T19:33:07.086638","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import random\nobj = random.choice(models)\n\nsegmentator.eval()\nsegmentator.cuda()\nwith torch.no_grad():\n    prediction = segmentator(obj[0][None, ...].cuda()).squeeze() >= 0\n\ncat = dm.val_dset.classes[obj[2]]\npc_show_matplotlib(obj[0], obj[1], cat, with_noise=True) # ground truth\npc_show_matplotlib(obj[0], prediction.cpu(), cat, with_noise=True) # prediction\npc_show_error_matplotlib(obj[0], obj[1], prediction.cpu(), cat)","metadata":{"execution":{"iopub.execute_input":"2021-06-21T19:51:44.690281Z","iopub.status.busy":"2021-06-21T19:51:44.689489Z","iopub.status.idle":"2021-06-21T19:51:56.445928Z","shell.execute_reply":"2021-06-21T19:51:56.446351Z","shell.execute_reply.started":"2021-06-20T13:29:31.484572Z"},"papermill":{"duration":11.867304,"end_time":"2021-06-21T19:51:56.446498","exception":false,"start_time":"2021-06-21T19:51:44.579194","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pc_show_ground_truth_vs_prediction(obj[0], obj[1], prediction, cat)\npc_show_error(obj[0], obj[1], prediction.cpu(), cat)","metadata":{"execution":{"iopub.execute_input":"2021-06-21T19:51:56.834935Z","iopub.status.busy":"2021-06-21T19:51:56.834165Z","iopub.status.idle":"2021-06-21T19:51:57.285773Z","shell.execute_reply":"2021-06-21T19:51:57.286182Z","shell.execute_reply.started":"2021-06-20T13:30:38.229492Z"},"papermill":{"duration":0.69367,"end_time":"2021-06-21T19:51:57.28633","exception":false,"start_time":"2021-06-21T19:51:56.59266","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]}]}